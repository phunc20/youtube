{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook elaborates on\n",
        "[this YouTube video clip](https://www.youtube.com/watch?v=OMDn66kM9Qc\n",
        "),\n",
        "where Alfredo Canziani introduced the audience to PyTorch (before the transition to PyTorch Lightning)."
      ],
      "metadata": {
        "id": "1XjBwNTHvXnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages and Their Configurations"
      ],
      "metadata": {
        "id": "KNiME7lyoLCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsXTjSSnn9nl",
        "outputId": "6c16a1ee-969a-4a25-e320-830ccb473454"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                            2.1.0+cu118\n",
            "torchaudio                       2.1.0+cu118\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qqq ipdb"
      ],
      "metadata": {
        "id": "SsSWQUikxhoV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zoNrCktFAOcO"
      },
      "outputs": [],
      "source": [
        "# import ipdb\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import random_split, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"dark_background\")"
      ],
      "metadata": {
        "id": "zTcImXeAn8u0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "k-Xd954UoPCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqTdxvA2s1Pn",
        "outputId": "3b3dba54-7c1b-4a3b-8737-4bb168c04b6c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def instantiate_our_simple_model(*, num_intermediate_neurons=64, dropout_proba=0.0):\n",
        "    \"\"\"\n",
        "    A simple multi-layer perceptron model\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(28*28, num_intermediate_neurons),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(num_intermediate_neurons, num_intermediate_neurons),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_proba),\n",
        "        nn.Linear(num_intermediate_neurons, 10),\n",
        "    )"
      ],
      "metadata": {
        "id": "uVHbW5cQoSLC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, *, num_intermediate_neurons=64, dropout_proba=0.0):\n",
        "        super().__init__()\n",
        "        self.h1 = nn.Linear(28*28, num_intermediate_neurons)\n",
        "        self.h2 = nn.Linear(num_intermediate_neurons, num_intermediate_neurons)\n",
        "        self.h3 = nn.Linear(num_intermediate_neurons, 10)\n",
        "        self.dropout = nn.Dropout(dropout_proba)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.h1(x)\n",
        "        a1 = F.relu(h1)\n",
        "        h2 = self.h2(a1)\n",
        "        a2 = F.relu(h2)\n",
        "        d2 = self.dropout(a1 + a2)\n",
        "        logits = self.h3(d2)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "GCTWRtxLRDbn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to play with the following **diff choices** of models."
      ],
      "metadata": {
        "id": "kgedpkfWbxHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = instantiate_our_simple_model()\n",
        "\n",
        "# A large enough model to notice the diff btw GPU and CPU training\n",
        "#model = instantiate_our_simple_model(num_intermediate_neurons=5_000)\n",
        "#model = instantiate_our_simple_model(num_intermediate_neurons=5_000, dropout_proba=0.1)\n",
        "\n",
        "#model = instantiate_our_simple_model(dropout_proba=0.1)\n",
        "model = ResNet(dropout_proba=0.1)\n",
        "\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQJr0YqxQk_d",
        "outputId": "8fde4f9f-93b9-4e3c-deb6-a246c4164327"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (h1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (h2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (h3): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if the model has successfully been moved to the right device:"
      ],
      "metadata": {
        "id": "TXe_pJzD1Si7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWSR99ir00YI",
        "outputId": "2c77cb9e-edd8-4f68-aac4-bc471b5877e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knDF0l6H1OvG",
        "outputId": "e7637227-ddb4-41be-91d1-8bba21dc2ae4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rmk.**  \n",
        "Note that `model.to(device)` is an **in-place** method of `nn.Module`. Indeed, it moves the entire model to `device` whereas `torch.Tensor.to` is **not in-place**.\n",
        "\n",
        "The following two cells try to illustrate this when `device` equals CUDA."
      ],
      "metadata": {
        "id": "EjO_fzwo2CK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.Tensor([1.,2.])\n",
        "t.to(device)\n",
        "t.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE4MYSvz1fCI",
        "outputId": "b51d407c-696e-48e0-a33a-7af424d1a501"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.Tensor([1.,2.])\n",
        "t = t.to(device)\n",
        "t.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg04XgWC14JV",
        "outputId": "5e29406d-cee1-4c74-99af-cf97c1795526"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimiser"
      ],
      "metadata": {
        "id": "K9UdQHSdcYIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "v1UlGvEScVMs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "7A4ANgnCcuyl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss/Objective Function"
      ],
      "metadata": {
        "id": "b8FKND8JdEtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0DeEtS1TdGc7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "JrWTxJ0GoYyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.MNIST(\n",
        "    \"data\",\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "num_val = int(len(dataset)*0.1)\n",
        "num_train = len(dataset) - num_val\n",
        "\n",
        "# For reproducibility\n",
        "rng_generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "train, val = random_split(\n",
        "    dataset,\n",
        "    lengths=[num_train, num_val],\n",
        "    generator=rng_generator,\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "num_workers = 2\n",
        "train_loader = DataLoader(\n",
        "    train, batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val, batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ZBxdg0bloZyt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{len(dataset)      = }')\n",
        "print(f'{len(train)        = }')\n",
        "print(f'{len(val)          = }')\n",
        "print(f'{len(train_loader) = }')\n",
        "print(f'{len(val_loader)   = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyihYSBP2yfK",
        "outputId": "07b000e5-ec0b-401b-918d-3150882079e2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(dataset)      = 60000\n",
            "len(train)        = 54000\n",
            "len(val)          = 6000\n",
            "len(train_loader) = 1688\n",
            "len(val_loader)   = 188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rmk.** `random_split` has already gotten randomness involved,\n",
        "so we may free us from specifying `shuffle=True` in `DataLoader`.\n",
        "\n",
        "Indeed, the first image in `dataset` is neither the first in `train` or in `val`."
      ],
      "metadata": {
        "id": "9Q6x2FsCtsh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(train[0][0], dataset[0][0]), \\\n",
        "torch.allclose(val[0][0], dataset[0][0]), \\\n",
        "torch.allclose(train[0][0], train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqAwptM0qdMM",
        "outputId": "21c112bb-e6a3-42ff-be6b-10f0ddfe9c87"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False, True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3)\n",
        "\n",
        "axes[0].imshow(dataset[0][0].reshape((28,28)), cmap=\"gray\")\n",
        "axes[0].set_title(\"dataset[0][0]\")\n",
        "axes[1].imshow(train[0][0].reshape((28,28)), cmap=\"gray\")\n",
        "axes[1].set_title(\"train[0][0]\")\n",
        "axes[2].imshow(val[0][0].reshape((28,28)), cmap=\"gray\")\n",
        "axes[2].set_title(\"val[0][0]\")\n",
        "\n",
        "for ax in axes:\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "mDa2UIoGrnyc",
        "outputId": "3db2941a-4f3b-4dea-9597-91074c75c60c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that\n",
        "- The data tensors' `requires_grad` equal `False`\n",
        "- The (trainable) parameters' equal `True`"
      ],
      "metadata": {
        "id": "aKyjJkIUAme3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{dataset[0][0].requires_grad               = }')\n",
        "print(f'{next(iter(train_loader))[1].requires_grad = }')\n",
        "print(f'{next(model.parameters()).requires_grad    = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pamCuv6AIzQ",
        "outputId": "49eaa0f0-cfaf-452e-d52b-833edb860cc2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset[0][0].requires_grad               = False\n",
            "next(iter(train_loader))[1].requires_grad = False\n",
            "next(model.parameters()).requires_grad    = True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{next(iter(train_loader))[0].shape = }')\n",
        "print(f'{next(iter(train_loader))[1].shape = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa1BxRdaFIoI",
        "outputId": "841288cc-5332-45bf-9a66-3fff25252c1c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "next(iter(train_loader))[0].shape = torch.Size([32, 1, 28, 28])\n",
            "next(iter(train_loader))[1].shape = torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Training Loop"
      ],
      "metadata": {
        "id": "CW4YlOTBdcD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "yA0waI8rz0yP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "start = time.perf_counter()\n",
        "for epoch in range(num_epochs):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        # ipdb.set_trace()\n",
        "        # pdb.set_trace()\n",
        "        x_cpu, y_cpu = batch\n",
        "        x_device = x_cpu.to(device)\n",
        "        y_device = y_cpu.to(device)\n",
        "        bs = x_device.shape[0]\n",
        "\n",
        "        # 1. Forward\n",
        "        # x_cpu.shape equals (bs, 1, 28, 28) but the model needs (bs, 28*28)\n",
        "        logits = model(x_device.view(bs, -1))\n",
        "\n",
        "        # 2. The objective function\n",
        "        J = loss(logits, y_device)\n",
        "\n",
        "        # 3. Clean the remains of the gradient\n",
        "        for param in model.parameters():\n",
        "            param.grad = None\n",
        "        # Or alternatively. Cf.\n",
        "        # https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
        "        #model.zero_grad(set_to_none=True)\n",
        "        # Or yet alternatively\n",
        "        #optimiser.zero_grad(set_to_none=True)\n",
        "\n",
        "        # 4. Accumulate the partial derivatives of J w.r.t. model.parameters()\n",
        "        J.backward()\n",
        "        # Or alternatively\n",
        "        #params.grad.add_(dJ/dparams)\n",
        "\n",
        "        # 5. Make a step\n",
        "        optimiser.step()\n",
        "        # Or alternatively\n",
        "        #with torch.no_grad():\n",
        "        #    params = params - eta * params.grad\n",
        "\n",
        "        batch_loss = J.item()\n",
        "        train_losses.append(batch_loss)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        # Make sure all tensors here have requires_grad equal to False\n",
        "        y_hat_device = torch.argmax(logits.detach(), dim=-1)\n",
        "        # print(f'{y_hat_device.requires_grad = }')\n",
        "        # Actually torch.argmax() seems to always return a torch.Tensor\n",
        "        # whose requires_grad equal to False, i.e. detach() extraneous\n",
        "        # pdb.set_trace()\n",
        "        y_true = y_cpu\n",
        "        y_pred = y_hat_device.to(\"cpu\")\n",
        "        # print(f'{y_pred.requires_grad = }')\n",
        "        #batch_acc = accuracy_score(y_true, y_pred)\n",
        "        # Or alternatively\n",
        "        batch_acc = y_true.eq(y_pred).float().mean().item()\n",
        "        train_accuracies.append(batch_acc)\n",
        "\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    model.eval()\n",
        "    for batch in val_loader:\n",
        "        x_cpu, y_cpu = batch\n",
        "        x_device = x_cpu.to(device)\n",
        "        y_device = y_cpu.to(device)\n",
        "        bs = x_device.shape[0]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_device.view(bs, -1))\n",
        "            J = loss(logits, y_device)\n",
        "\n",
        "        batch_loss = J.item()\n",
        "        val_losses.append(batch_loss)\n",
        "\n",
        "        y_hat_device = torch.argmax(logits.detach(), dim=-1)\n",
        "        y_true = y_cpu\n",
        "        y_pred = y_hat_device.to(\"cpu\")\n",
        "        batch_acc = accuracy_score(y_true, y_pred)\n",
        "        val_accuracies.append(batch_acc)\n",
        "\n",
        "    print(f'(epoch {epoch+1}) train loss = {sum(train_losses)/len(train_losses):.4f} '\n",
        "          f'train acc = {sum(train_accuracies)/len(train_accuracies):.2f}\\n'\n",
        "          f'          val loss   = {sum(val_losses)/len(val_losses):.4f} '\n",
        "          f'val acc   = {sum(val_accuracies)/len(val_accuracies):.2f}'\n",
        "    )\n",
        "\n",
        "end = time.perf_counter()\n",
        "print(f'Took {end-start:.2f} sec to run {num_epochs} epochs')"
      ],
      "metadata": {
        "id": "tG-kVdpCqjn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7664ffb-5969-487d-8111-c51161f93a77"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch 1) train loss = 0.8394 train acc = 0.78\n",
            "          val loss   = 0.3924 val acc   = 0.89\n",
            "(epoch 2) train loss = 0.3705 train acc = 0.89\n",
            "          val loss   = 0.3150 val acc   = 0.91\n",
            "(epoch 3) train loss = 0.3075 train acc = 0.91\n",
            "          val loss   = 0.2750 val acc   = 0.92\n",
            "(epoch 4) train loss = 0.2695 train acc = 0.92\n",
            "          val loss   = 0.2457 val acc   = 0.93\n",
            "(epoch 5) train loss = 0.2384 train acc = 0.93\n",
            "          val loss   = 0.2203 val acc   = 0.93\n",
            "Took 64.19 sec to run 5 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q&A\n",
        "1. Can `DataLoader` be told where to put the data? (I.e. `device` as an input arg)\n",
        "    - Yes, but it seems that this is discouraged; rather, `pin_memory=True` is encouraged for CPU-to-CUDA data copying.\n",
        "2. Training `model = instantiate_our_simple_model()`\n",
        "   (i.e. with the default `num_intermediat_neurons=64`)\n",
        "   on CPU and on T4 doesn't seem to give much efficiency diff. Where is the problem? Besides,\n",
        "   when debugging for this, why raising `batch_size`\n",
        "   doesn't make GPU/CPU RAM usage increase significantly?\n",
        "    - Too small a NN model. Try with, say, `model = instantiate_our_simple_model(num_intermediate_neurons=5_000)` and you'll see the diff btw CPU and GPU efficiencies.\n",
        "    - RAM usage is insignificant even when we raise\n",
        "      `batch_size` to, say, `8192`. This is due to\n",
        "      the fact that the MNIST image is small. Indeed,\n",
        "      with the shape of `(1, 28, 28)`, a `float32` MNIST image is `28 * 28 * 4` Bytes, which is less than `4` KB. A batch of `8192` such images\n",
        "      occupies **only about `32` MB of RAM**.\n",
        "    - The following code cells are borrowed from\n",
        "      [CUDA.jl](https://cuda.juliagpu.org/stable/tutorials/introduction/)\n",
        "      and could help us confirm that GPU is working\n",
        "      properly (provided that we choose T4/V100/A100 GPU for the runtime)."
      ],
      "metadata": {
        "id": "FlbSG-WQx628"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2**20\n",
        "a_cpu = torch.full((N,), fill_value=1.0, dtype=torch.float32, device=\"cpu\")\n",
        "b_cpu = torch.full((N,), fill_value=2.0, dtype=torch.float32, device=\"cpu\")\n",
        "a_cuda = torch.full((N,), fill_value=1.0, dtype=torch.float32, device=\"cuda\")\n",
        "b_cuda = torch.full((N,), fill_value=2.0, dtype=torch.float32, device=\"cuda\")"
      ],
      "metadata": {
        "id": "Bs3lsGZr7X1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit a_cpu + b_cpu"
      ],
      "metadata": {
        "id": "wlPi4UXZS5Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit a_cuda + b_cuda"
      ],
      "metadata": {
        "id": "6NabhNHuS7y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why did Alfredo emphasize on that `J.backward()` **accumulates**, instead of computes, the gradient?\n",
        "    - Note that, even before we are able to answer this, we could try to disable/comment **Step 3** in the training code while leaving the other steps unchanged\n",
        "    ```python\n",
        "    #for param in model.parameters():\n",
        "    #    param.grad = None\n",
        "    ```\n",
        "    And the training/validation metrics will soon\n",
        "    make us realize that this step is **indispensible**."
      ],
      "metadata": {
        "id": "T9VYZATCAQVE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "otd0Vy2VS2Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Note that in this particular MNIST example, `batch_size = 32` is a lot better than a super big `batch_size = 8192`, which is the diff btw mini-batch and batch training.\n",
        "5. `ResNet` **converges faster** than the simpler model because residual mechanism kind of resolves the problem of vanishing gradient by making the route to the lower layers shallower/shorter.\n",
        "6. We could predict the loss at the beginning of our training to be $(\\ln 10)$"
      ],
      "metadata": {
        "id": "Q7q7F40-CcV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.log(torch.Tensor([10]))"
      ],
      "metadata": {
        "id": "1VishJd-CvgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3abcd30-38ba-4dfd-9d4b-76b279776a16"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.3026])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQeRDK8X12zA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}